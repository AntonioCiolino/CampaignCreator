# Example Database Connection (PostgreSQL)
DATABASE_URL="postgresql://user:password@host:port/dbname"

# --- API Keys for External Services ---
# The keys below (OPENAI_API_KEY, GEMINI_API_KEY, etc.) are system-wide defaults.
# For services like OpenAI and Stable Diffusion, which support Bring Your Own Key (BYOK),
# these system keys can be used as fallbacks for superusers if they haven't
# provided their own keys via their user settings.
# Non-superusers MUST provide their own keys for these BYOK-enabled services.
# If a system key is not configured here, superusers will also need to provide their own.

# LLM API Keys
OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
GEMINI_API_KEY="YOUR_GEMINI_API_KEY"

# Llama Configuration (API Key is often for a specific provider or local setup, URL for self-hosted/custom endpoint)
LLAMA_API_KEY="YOUR_LLAMA_API_KEY"
LLAMA_API_URL="" # e.g., http://localhost:11434/v1 if using Ollama with an OpenAI-compatible API

# DeepSeek API Key
DEEPSEEK_API_KEY="YOUR_DEEPSEEK_API_KEY"

# OpenAI DALL-E Image Generation Settings
# OPENAI_API_KEY is used for DALL-E authentication as well.
OPENAI_DALLE_MODEL_NAME="dall-e-3"
OPENAI_DALLE_DEFAULT_IMAGE_SIZE="1024x1024" # Supported for DALL-E 3: "1024x1024", "1792x1024", "1024x1792"
OPENAI_DALLE_DEFAULT_IMAGE_QUALITY="standard" # Supported for DALL-E 3: "standard", "hd"

# Stable Diffusion Image Generation Settings
# Base URL for the Stable Diffusion API. Defaults to Stability AI's public API.
# For Stability AI, use "https://api.stability.ai". For other providers or local instances, change accordingly.
STABLE_DIFFUSION_API_BASE_URL="https://api.stability.ai"
# API Key for Stable Diffusion (e.g. Stability AI). Required if using the public API or a key-protected custom API.
STABLE_DIFFUSION_API_KEY="YOUR_STABLE_DIFFUSION_API_KEY_HERE"
# Default engine/model to use for Stable Diffusion if not specified by the client.
# Valid engines are defined in STABLE_DIFFUSION_ENGINES in config.py (e.g., "core", "ultra", "sd3").
# Example engine IDs for Stability AI: "stable-diffusion-xl-1024-v1-0", "stable-diffusion-v1-6", "sd3", "sd3-turbo"
# Check your provider's documentation for available engine IDs.
STABLE_DIFFUSION_DEFAULT_ENGINE="stable-diffusion-xl-1024-v1-0" # Example, adjust to a valid engine for your setup

# Generic Local LLM Provider (OpenAI-Compatible API)
# This name is used as a key in the LLM factory to identify this service.
LOCAL_LLM_PROVIDER_NAME="local_llm"
# Example for Ollama's OpenAI compatible endpoint. Adjust if your local server runs elsewhere.
LOCAL_LLM_API_BASE_URL="http://localhost:11434/v1" 
# Optional: Default model to use if client doesn't specify one for this provider.
# The exact ID depends on the models available on your local server (e.g., "mistral:latest", "llama3:latest", or just "mistral").
LOCAL_LLM_DEFAULT_MODEL_ID="mistral:latest"


# JWT Settings (example)
# SECRET_KEY="your_very_secret_key_for_jwt_signing"
# ALGORITHM="HS256"
# ACCESS_TOKEN_EXPIRE_MINUTES=30

PORT=8000

# Azure Blob Storage Settings
AZURE_STORAGE_ACCOUNT_NAME=your_azure_storage_account_name
AZURE_STORAGE_CONTAINER_NAME=campaignimages
AZURE_STORAGE_CONNECTION_STRING=your_azure_storage_connection_string

# If using DefaultAzureCredential with a Service Principal (instead of Connection String):
# AZURE_CLIENT_ID=your_service_principal_client_id
# AZURE_TENANT_ID=your_service_principal_tenant_id
# AZURE_CLIENT_SECRET=your_service_principal_client_secret
